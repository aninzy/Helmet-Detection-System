{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
    "MODELS_DIR = os.path.join('pre-trained-model')\n",
    "for dir in [MODELS_DIR]:\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_directory = 'models'\n",
    "subfolder_name = 'ssd_resnet50_v1_fpn_640x640' #Change\n",
    "\n",
    "main_directory_path = os.path.join(os.getcwd(), main_directory)\n",
    "subfolder_path = os.path.join(main_directory_path, subfolder_name)\n",
    "\n",
    "if not os.path.exists(subfolder_path):\n",
    "    os.makedirs(subfolder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Download and extract model\n",
    "MODEL_DATE = '20200711' #Change\n",
    "MODEL_NAME = 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8' #Change\n",
    "MODEL_TAR_FILENAME = MODEL_NAME + '.tar.gz'\n",
    "MODELS_DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/'\n",
    "MODEL_DOWNLOAD_LINK = MODELS_DOWNLOAD_BASE + MODEL_DATE + '/' + MODEL_TAR_FILENAME\n",
    "PATH_TO_MODEL_TAR = os.path.join(MODELS_DIR, MODEL_TAR_FILENAME)\n",
    "PATH_TO_CKPT = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'checkpoint/'))\n",
    "PATH_TO_CFG = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'pipeline.config'))\n",
    "if not os.path.exists(PATH_TO_CKPT):\n",
    "    print('Downloading model. This may take a while... ', end='')\n",
    "    urllib.request.urlretrieve(MODEL_DOWNLOAD_LINK, PATH_TO_MODEL_TAR)\n",
    "    tar_file = tarfile.open(PATH_TO_MODEL_TAR)\n",
    "    tar_file.extractall(MODELS_DIR)\n",
    "    tar_file.close()\n",
    "    os.remove(PATH_TO_MODEL_TAR)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = '../training_helper_directory'\n",
    "SCRIPT_PATH = WORKSPACE_PATH + '/scripts'\n",
    "ANNOTATION_PATH = WORKSPACE_PATH + '/annotations'\n",
    "\n",
    "IMAGE_PATH = '../Dataset/\"PASCAL VOC Format Dataset\"'\n",
    "\n",
    "CUSTOM_MODEL_NAME = '/ssd_resnet50_v1_fpn_640x640' #Change: same as subfolder name\n",
    "MODEL_PATH = './models' + CUSTOM_MODEL_NAME\n",
    "\n",
    "PRETRAINED_PATH = './pre-trained-model/' + MODEL_NAME\n",
    "CONFIG_PATH = MODEL_PATH + '/pipeline.config'\n",
    "\n",
    "EXPORT_PATH = '../exported-models/my-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: ../training_helper_directory/annotations/train.record\n",
      "Successfully created the TFRecord file: ../training_helper_directory/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "# Create train data:\n",
    "!python {SCRIPT_PATH + '/generate_tfrecord.py'} -x {IMAGE_PATH + '/train'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/train.record'}\n",
    "\n",
    "# Create test data:\n",
    "!python {SCRIPT_PATH + '/generate_tfrecord.py'} -x {IMAGE_PATH + '/test'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/test.record'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH = \"D:\\Helmet Detection System\\SSD ResNet50 V1 FPN 640x640\\pre-trained-model\\ssd_resnet50_v1_fpn_640x640_coco17_tpu-8\\pipeline.config\" #Change\n",
    "DESTINATION_PATH = \"D:\\Helmet Detection System\\SSD ResNet50 V1 FPN 640x640\\models\\ssd_resnet50_v1_fpn_640x640\" #Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1 file(s) copied.\n"
     ]
    }
   ],
   "source": [
    "!copy \"{SOURCE_PATH}\" \"{DESTINATION_PATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ssd {\n",
       "   num_classes: 90\n",
       "   image_resizer {\n",
       "     fixed_shape_resizer {\n",
       "       height: 640\n",
       "       width: 640\n",
       "     }\n",
       "   }\n",
       "   feature_extractor {\n",
       "     type: \"ssd_resnet50_v1_fpn_keras\"\n",
       "     depth_multiplier: 1.0\n",
       "     min_depth: 16\n",
       "     conv_hyperparams {\n",
       "       regularizer {\n",
       "         l2_regularizer {\n",
       "           weight: 0.00039999998989515007\n",
       "         }\n",
       "       }\n",
       "       initializer {\n",
       "         truncated_normal_initializer {\n",
       "           mean: 0.0\n",
       "           stddev: 0.029999999329447746\n",
       "         }\n",
       "       }\n",
       "       activation: RELU_6\n",
       "       batch_norm {\n",
       "         decay: 0.996999979019165\n",
       "         scale: true\n",
       "         epsilon: 0.0010000000474974513\n",
       "       }\n",
       "     }\n",
       "     override_base_feature_extractor_hyperparams: true\n",
       "     fpn {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "     }\n",
       "   }\n",
       "   box_coder {\n",
       "     faster_rcnn_box_coder {\n",
       "       y_scale: 10.0\n",
       "       x_scale: 10.0\n",
       "       height_scale: 5.0\n",
       "       width_scale: 5.0\n",
       "     }\n",
       "   }\n",
       "   matcher {\n",
       "     argmax_matcher {\n",
       "       matched_threshold: 0.5\n",
       "       unmatched_threshold: 0.5\n",
       "       ignore_thresholds: false\n",
       "       negatives_lower_than_unmatched: true\n",
       "       force_match_for_each_row: true\n",
       "       use_matmul_gather: true\n",
       "     }\n",
       "   }\n",
       "   similarity_calculator {\n",
       "     iou_similarity {\n",
       "     }\n",
       "   }\n",
       "   box_predictor {\n",
       "     weight_shared_convolutional_box_predictor {\n",
       "       conv_hyperparams {\n",
       "         regularizer {\n",
       "           l2_regularizer {\n",
       "             weight: 0.00039999998989515007\n",
       "           }\n",
       "         }\n",
       "         initializer {\n",
       "           random_normal_initializer {\n",
       "             mean: 0.0\n",
       "             stddev: 0.009999999776482582\n",
       "           }\n",
       "         }\n",
       "         activation: RELU_6\n",
       "         batch_norm {\n",
       "           decay: 0.996999979019165\n",
       "           scale: true\n",
       "           epsilon: 0.0010000000474974513\n",
       "         }\n",
       "       }\n",
       "       depth: 256\n",
       "       num_layers_before_predictor: 4\n",
       "       kernel_size: 3\n",
       "       class_prediction_bias_init: -4.599999904632568\n",
       "     }\n",
       "   }\n",
       "   anchor_generator {\n",
       "     multiscale_anchor_generator {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       anchor_scale: 4.0\n",
       "       aspect_ratios: 1.0\n",
       "       aspect_ratios: 2.0\n",
       "       aspect_ratios: 0.5\n",
       "       scales_per_octave: 2\n",
       "     }\n",
       "   }\n",
       "   post_processing {\n",
       "     batch_non_max_suppression {\n",
       "       score_threshold: 9.99999993922529e-09\n",
       "       iou_threshold: 0.6000000238418579\n",
       "       max_detections_per_class: 100\n",
       "       max_total_detections: 100\n",
       "       use_static_shapes: false\n",
       "     }\n",
       "     score_converter: SIGMOID\n",
       "   }\n",
       "   normalize_loss_by_num_matches: true\n",
       "   loss {\n",
       "     localization_loss {\n",
       "       weighted_smooth_l1 {\n",
       "       }\n",
       "     }\n",
       "     classification_loss {\n",
       "       weighted_sigmoid_focal {\n",
       "         gamma: 2.0\n",
       "         alpha: 0.25\n",
       "       }\n",
       "     }\n",
       "     classification_weight: 1.0\n",
       "     localization_weight: 1.0\n",
       "   }\n",
       "   encode_background_as_zeros: true\n",
       "   normalize_loc_loss_by_codesize: true\n",
       "   inplace_batchnorm_update: true\n",
       "   freeze_batchnorm: false\n",
       " },\n",
       " 'train_config': batch_size: 64\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_crop_image {\n",
       "     min_object_covered: 0.0\n",
       "     min_aspect_ratio: 0.75\n",
       "     max_aspect_ratio: 3.0\n",
       "     min_area: 0.75\n",
       "     max_area: 1.0\n",
       "     overlap_thresh: 0.0\n",
       "   }\n",
       " }\n",
       " sync_replicas: true\n",
       " optimizer {\n",
       "   momentum_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.03999999910593033\n",
       "         total_steps: 25000\n",
       "         warmup_learning_rate: 0.013333000242710114\n",
       "         warmup_steps: 2000\n",
       "       }\n",
       "     }\n",
       "     momentum_optimizer_value: 0.8999999761581421\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
       " num_steps: 25000\n",
       " startup_delay_steps: 0.0\n",
       " replicas_to_aggregate: 8\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false\n",
       " fine_tune_checkpoint_type: \"classification\"\n",
       " use_bfloat16: true\n",
       " fine_tune_checkpoint_version: V2,\n",
       " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " },\n",
       " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false,\n",
       " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }\n",
       " ],\n",
       " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = 2 #Change\n",
    "\n",
    "pipeline_config.train_config.batch_size = 1 #Change\n",
    "pipeline_config.train_config.num_steps = 20000 #Change\n",
    "pipeline_config.train_config.use_bfloat16 = False\n",
    "\n",
    "pipeline_config.train_config.fine_tune_checkpoint = PRETRAINED_PATH + '/checkpoint/ckpt-0'\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\" \n",
    "\n",
    "pipeline_config.train_input_reader.label_map_path = ANNOTATION_PATH + '/label_map.pbtxt'\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [ANNOTATION_PATH+ '/train.record'] \n",
    "\n",
    "pipeline_config.eval_input_reader[0].label_map_path = ANNOTATION_PATH + '/label_map.pbtxt'\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/test.record']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "with tf.io.gfile.GFile(CONFIG_PATH, \"wb\") as f:\n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Helmet Detection System\\\\SSD ResNet50 V1 FPN 640x640'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python {SCRIPT_PATH + '/model_main_tf2.py'} --model_dir={MODEL_PATH} --pipeline_config_path={MODEL_PATH + '/pipeline.config'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python {SCRIPT_PATH + '/exporter_main_v2.py'} --input_type image_tensor --pipeline_config_path {CONFIG_PATH} --trained_checkpoint_dir {MODEL_PATH + '/' } --output_directory exported-models\\my-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done! Took 8.411863327026367 seconds\n",
      "Running inference for D:/Helmet Detection System/Dataset/PASCAL VOC Format Dataset/test/BikesHelmets392_png.rf.9802b10c090e222ccda1a9c575875961.jpg... Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Object Detection (On Image) From TF2 Saved Model\n",
    "=====================================\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import argparse\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Enable GPU dynamic memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# PROVIDE PATH TO IMAGE DIRECTORY\n",
    "IMAGE_PATHS = 'D:/Helmet Detection System/Dataset/PASCAL VOC Format Dataset/test/BikesHelmets392_png.rf.9802b10c090e222ccda1a9c575875961.jpg' #Change\n",
    "\n",
    "# PROVIDE PATH TO MODEL DIRECTORY\n",
    "PATH_TO_MODEL_DIR = './exported-models/my-model'\n",
    "\n",
    "# PROVIDE PATH TO LABEL MAP\n",
    "PATH_TO_LABELS = ANNOTATION_PATH + '/label_map.pbtxt'\n",
    "\n",
    "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
    "MIN_CONF_THRESH = float(0.60)\n",
    "\n",
    "# LOAD THE MODEL\n",
    "\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))\n",
    "\n",
    "# LOAD LABEL MAP DATA FOR PLOTTING\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
    "\n",
    "image = cv2.imread(IMAGE_PATHS)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image_expanded = np.expand_dims(image_rgb, axis=0)\n",
    "\n",
    "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "input_tensor = tf.convert_to_tensor(image)\n",
    "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "# input_tensor = np.expand_dims(image_np, 0)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "# All outputs are batches tensors.\n",
    "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "# We're only interested in the first num_detections.\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "               for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "image_with_detections = image.copy()\n",
    "\n",
    "# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_with_detections,\n",
    "      detections['detection_boxes'],\n",
    "      detections['detection_classes'],\n",
    "      detections['detection_scores'],\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      max_boxes_to_draw=100,\n",
    "      min_score_thresh=0.5,\n",
    "      agnostic_mode=False)\n",
    "\n",
    "print('Done')\n",
    "# DISPLAYS OUTPUT IMAGE\n",
    "cv2.imshow('test', image_with_detections)\n",
    "# CLOSES WINDOW ONCE KEY IS PRESSED\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.38s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.294\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.055\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.403\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0314 23:17:44.874699 18576 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "I0314 23:17:44.874699 18576 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0314 23:17:44.874699 18576 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0314 23:17:44.875696 18576 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0314 23:17:44.875696 18576 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "INFO:tensorflow:Reading unweighted datasets: ['../training_helper_directory/annotations/test.record']\n",
      "I0314 23:17:46.446702 18576 dataset_builder.py:162] Reading unweighted datasets: ['../training_helper_directory/annotations/test.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['../training_helper_directory/annotations/test.record']\n",
      "I0314 23:17:46.447746 18576 dataset_builder.py:79] Reading record datasets for input file: ['../training_helper_directory/annotations/test.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0314 23:17:46.447746 18576 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0314 23:17:46.447746 18576 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From c:\\Users\\sudee\\.conda\\envs\\helmet\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0314 23:17:46.452435 18576 deprecation.py:350] From c:\\Users\\sudee\\.conda\\envs\\helmet\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From c:\\Users\\sudee\\.conda\\envs\\helmet\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0314 23:17:46.472086 18576 deprecation.py:350] From c:\\Users\\sudee\\.conda\\envs\\helmet\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From c:\\Users\\sudee\\.conda\\envs\\helmet\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0314 23:17:49.074336 18576 deprecation.py:350] From c:\\Users\\sudee\\.conda\\envs\\helmet\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From c:\\Users\\sudee\\.conda\\envs\\helmet\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0314 23:17:49.918708 18576 deprecation.py:350] From c:\\Users\\sudee\\.conda\\envs\\helmet\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Waiting for new checkpoint at ./models/ssd_resnet50_v1_fpn_640x640\n",
      "I0314 23:17:51.601169 18576 checkpoint_utils.py:136] Waiting for new checkpoint at ./models/ssd_resnet50_v1_fpn_640x640\n",
      "INFO:tensorflow:Found new checkpoint at ./models/ssd_resnet50_v1_fpn_640x640\\ckpt-21\n",
      "I0314 23:17:51.609391 18576 checkpoint_utils.py:145] Found new checkpoint at ./models/ssd_resnet50_v1_fpn_640x640\\ckpt-21\n",
      "c:\\Users\\sudee\\.conda\\envs\\helmet\\lib\\site-packages\\keras\\backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "I0314 23:17:55.692880 18576 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
      "I0314 23:18:05.078245 18576 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
      "WARNING:tensorflow:From c:\\Users\\sudee\\.conda\\envs\\helmet\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0314 23:18:14.804865 18576 deprecation.py:350] From c:\\Users\\sudee\\.conda\\envs\\helmet\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Finished eval step 0\n",
      "I0314 23:18:14.933209 18576 model_lib_v2.py:966] Finished eval step 0\n",
      "WARNING:tensorflow:From c:\\Users\\sudee\\.conda\\envs\\helmet\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W0314 23:18:15.296262 18576 deprecation.py:350] From c:\\Users\\sudee\\.conda\\envs\\helmet\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "INFO:tensorflow:Finished eval step 100\n",
      "I0314 23:18:25.910482 18576 model_lib_v2.py:966] Finished eval step 100\n",
      "INFO:tensorflow:Performing evaluation on 126 images.\n",
      "I0314 23:18:28.029861 18576 coco_evaluation.py:293] Performing evaluation on 126 images.\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0314 23:18:28.030858 18576 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.01s)\n",
      "I0314 23:18:28.035915 18576 coco_tools.py:138] DONE (t=0.01s)\n",
      "INFO:tensorflow:Eval metrics at step 20000\n",
      "I0314 23:18:28.528934 18576 model_lib_v2.py:1015] Eval metrics at step 20000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.141041\n",
      "I0314 23:18:28.570019 18576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.141041\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.294114\n",
      "I0314 23:18:28.571015 18576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.294114\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.114157\n",
      "I0314 23:18:28.572657 18576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.114157\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.055486\n",
      "I0314 23:18:28.573656 18576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.055486\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.142852\n",
      "I0314 23:18:28.573656 18576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.142852\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.218376\n",
      "I0314 23:18:28.574842 18576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.218376\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.154305\n",
      "I0314 23:18:28.574842 18576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.154305\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.340613\n",
      "I0314 23:18:28.574842 18576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.340613\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.403034\n",
      "I0314 23:18:28.576330 18576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.403034\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.184659\n",
      "I0314 23:18:28.576330 18576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.184659\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.418206\n",
      "I0314 23:18:28.577814 18576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.418206\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.598333\n",
      "I0314 23:18:28.579437 18576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.598333\n",
      "INFO:tensorflow:\t+ Loss/localization_loss: 0.283232\n",
      "I0314 23:18:28.580455 18576 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.283232\n",
      "INFO:tensorflow:\t+ Loss/classification_loss: 0.535254\n",
      "I0314 23:18:28.580455 18576 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.535254\n",
      "INFO:tensorflow:\t+ Loss/regularization_loss: 0.899543\n",
      "I0314 23:18:28.581440 18576 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.899543\n",
      "INFO:tensorflow:\t+ Loss/total_loss: 1.718029\n",
      "I0314 23:18:28.582437 18576 model_lib_v2.py:1018] \t+ Loss/total_loss: 1.718029\n",
      "INFO:tensorflow:Exiting evaluation at step 20000\n",
      "I0314 23:18:28.973855 18576 model_lib_v2.py:1168] Exiting evaluation at step 20000\n"
     ]
    }
   ],
   "source": [
    "!python {SCRIPT_PATH + '/model_main_tf2.py'} --model_dir={MODEL_PATH} --pipeline_config_path={MODEL_PATH + '/pipeline.config'} --checkpoint_dir={MODEL_PATH}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helmet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
